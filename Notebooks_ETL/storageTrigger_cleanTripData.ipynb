{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Crea cliente para interactuar con Cloud Storage\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Función de limpieza\n",
    "def clean_data_yellow(df):\n",
    "    # Limpieza de valores faltantes\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "    median_values = {\n",
    "        'passenger_count': df['passenger_count'].median(),\n",
    "        'ratecodeid': df['ratecodeid'].median(),\n",
    "        'congestion_surcharge': df['congestion_surcharge'].median(),\n",
    "        'airport_fee': df['airport_fee'].median()\n",
    "    }\n",
    "\n",
    "    mode_value = df['store_and_fwd_flag'].mode()[0]\n",
    "\n",
    "    df.fillna(median_values, inplace=True)\n",
    "    df['store_and_fwd_flag'].fillna(mode_value, inplace=True)\n",
    "\n",
    "    # Corrección de valores anómalos\n",
    "    distance_limit = 100\n",
    "    fare_lower_limit = 0\n",
    "    fare_upper_limit = 500\n",
    "\n",
    "    # Crear una máscara de filtro y aplicar el filtro\n",
    "    filter_mask = (df['trip_distance'] <= distance_limit) & \\\n",
    "                  (df['fare_amount'] >= fare_lower_limit) & \\\n",
    "                  (df['fare_amount'] <= fare_upper_limit)\n",
    "\n",
    "    # Crear una copia del DataFrame filtrado para evitar SettingWithCopyWarning\n",
    "    df = df.loc[filter_mask].copy()\n",
    "\n",
    "    # Normalización y enriquecimiento de datos\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "    # Conversión a entero con manejo de valores no numéricos o infinitos\n",
    "    df['passenger_count'] = pd.to_numeric(df['passenger_count'], errors='coerce').fillna(0).astype(int)\n",
    "    df['ratecodeid'] = pd.to_numeric(df['ratecodeid'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Tratamiento de registros duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_data_green(df):\n",
    "    # Limpieza de valores faltantes\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "    # Normalización de datos\n",
    "    df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "    df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "\n",
    "    # Conversión a entero con manejo de valores no numéricos o infinitos\n",
    "    df['ehail_fee'] = pd.to_numeric(df['ehail_fee'], errors='coerce').fillna(0).astype(float)\n",
    "    df['passenger_count'] = pd.to_numeric(df['passenger_count'], errors='coerce').fillna(0).astype(int)\n",
    "    df['payment_type'] = pd.to_numeric(df['payment_type'], errors='coerce').fillna(0).astype(int)\n",
    "    df['ratecodeid'] = pd.to_numeric(df['ratecodeid'], errors='coerce').fillna(0).astype(int)\n",
    "    df['trip_type'] = pd.to_numeric(df['trip_type'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Tratamiento de registros duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_data_alquiler(df):\n",
    "    # Crear una copia del DataFrame para evitar modificar el original\n",
    "    df = df.copy()\n",
    "\n",
    "    # Limpieza de valores faltantes\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "    # Normalización de datos\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "    df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])\n",
    "\n",
    "    # Conversión a entero con manejo de valores no numéricos o infinitos\n",
    "    df['pulocationid'] = pd.to_numeric(df['pulocationid'], errors='coerce').fillna(0).astype(int)\n",
    "    df['dolocationid'] = pd.to_numeric(df['dolocationid'], errors='coerce').fillna(0).astype(int)\n",
    "    df['sr_flag'] = pd.to_numeric(df['sr_flag'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Tratamiento de registros duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_and_store_data(data, context):\n",
    "\n",
    "    # El nombre del bucket y el nombre del archivo se obtienen del contexto del evento\n",
    "    bucket_name = data['bucket']\n",
    "    file_name = data['name']\n",
    "\n",
    "    # Verifica si el archivo se encuentra en la carpeta correspondiente\n",
    "    if (file_name.startswith('data/taxis-amarillos/') or \n",
    "        file_name.startswith('data/taxis-verdes/') or \n",
    "        file_name.startswith('data/taxis-alquiler/')):\n",
    "\n",
    "        try:\n",
    "            # Leer datos del bucket\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(file_name)\n",
    "            data = blob.download_as_bytes()\n",
    "            df = pd.read_parquet(io.BytesIO(data))\n",
    "            print(f\"Datos leídos del bucket {bucket_name}.\")\n",
    "\n",
    "            # Aplicar las reglas de limpieza\n",
    "            if file_name.startswith('data/taxis-amarillos/'):\n",
    "                df_cleaned = clean_data_yellow(df)\n",
    "            elif file_name.startswith('data/taxis-verdes/'):\n",
    "                df_cleaned = clean_data_green(df)\n",
    "            elif file_name.startswith('data/taxis-alquiler/'):\n",
    "                df_cleaned = clean_data_alquiler(df)\n",
    "            \n",
    "            print(\"Datos limpiados.\")\n",
    "\n",
    "            # Guardar datos limpios en el nuevo bucket\n",
    "            cleaned_bucket_name = 'ecoride-data'\n",
    "            if file_name.startswith('data/taxis-amarillos/'):\n",
    "                cleaned_file_name = 'pre-data/taxis-amarillos/cleaned_' + os.path.basename(file_name)\n",
    "            elif file_name.startswith('data/taxis-verdes/'):\n",
    "                cleaned_file_name = 'pre-data/taxis-verdes/cleaned_' + os.path.basename(file_name)\n",
    "            elif file_name.startswith('data/taxis-alquiler/'):\n",
    "                cleaned_file_name = 'pre-data/taxis-alquiler/cleaned_' + os.path.basename(file_name)\n",
    "            cleaned_blob = storage_client.bucket(cleaned_bucket_name).blob(cleaned_file_name)\n",
    "\n",
    "            # Convertir DataFrame a Parquet y subirlo\n",
    "            buffer = io.BytesIO()\n",
    "            df_cleaned.to_parquet(buffer)\n",
    "            cleaned_blob.upload_from_string(buffer.getvalue(), content_type='application/octet-stream')\n",
    "            print(f\"Archivo limpio guardado en: gs://{cleaned_bucket_name}/{cleaned_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(\"Se produjo un error:\", e)\n",
    "    else:\n",
    "        print(f\"Ignorando archivo fuera de las carpetas especificadas: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
